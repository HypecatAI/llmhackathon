import os
from typing import List, Iterator, Iterable

import google.generativeai as genai
import instructor
import itertools
import pandas as pd
from dotenv import load_dotenv
from pydantic import BaseModel, Field
from tqdm import tqdm

from domain.dialogue_manager import Intent


class CustomerSupportDatasetSchema(BaseModel):
    flags: str = Field(..., description="Flags associated with the instruction.")
    instruction: str = Field(..., description="The instruction text.")
    category: str = Field(..., description="Category to which the instruction belongs.")
    intent: str = Field(..., description="Intent related to the instruction.")
    response: str = Field(..., description="The response associated with the instruction.")
    intent_enum: str = Field(..., description="Enumerated value for the intent.")

class Ticket(BaseModel):
    """Represents a customer service ticket."""
    ticket_id: int
    content: str

class PredictedTicket(BaseModel):
    """Represents a ticket with predicted intent."""
    ticket_id: int
    predicted_intent: Intent

class BatchPredictionResponse(BaseModel):
    """Represents a batch of predicted tickets."""
    predictions: List[PredictedTicket]

class IntentPredictor:
    """Predicts intents for customer service tickets using the Gemini model."""

    def __init__(self) -> None:
        """Initialize the IntentPredictor with Gemini model configuration."""
        load_dotenv()
        genai.configure(api_key=os.getenv("GOOGLE_API_KEY"))
        self.model = genai.GenerativeModel('gemini-1.5-flash')
        self.client = instructor.from_gemini(client=self.model, mode=instructor.Mode.GEMINI_JSON)
        self.system_message = """
        You are an AI assistant for predicting customer service ticket intents. Analyze the given tickets and provide intent predictions.
        """

    def predict_intents(self, tickets: List[Ticket]) -> BatchPredictionResponse:
        """
        Predict intents for a list of tickets.

        Args:
            tickets (List[Ticket]): List of tickets to predict intents for.

        Returns:
            BatchPredictionResponse: Predicted intents and confidence scores.
        """
        prompt = f"""
        Given the following customer service tickets, predict the intent for each:

        Tickets:
        {self._format_tickets(tickets)}

        Respond with a list of predictions, including the ticket ID, predicted intent, and confidence score.
        """

        messages = [
            {"role": "system", "content": self.system_message},
            {"role": "user", "content": prompt}
        ]

        return self.client.chat.completions.create(
            messages=messages,
            max_retries=0,
            strict=False,
            response_model=BatchPredictionResponse
        )

    @staticmethod
    def _format_tickets(tickets: List[Ticket]) -> str:
        """
        Format a list of tickets into a string.

        Args:
            tickets (List[Ticket]): List of tickets to format.

        Returns:
            str: Formatted string of tickets.
        """
        return "\n".join([f"Ticket {ticket.ticket_id}: {ticket.content}" for ticket in tickets])

def read_prepared_dataset(file_path: str, num_tickets: int = 5000) -> pd.DataFrame:
    """
    Read the CSV file generated by prepare_dataset.py, add a Ticket_Id column,
    shuffle the dataset, and limit to the specified number of tickets.

    Args:
        file_path (str): Path to the CSV file.
        num_tickets (int): Number of tickets to process. Defaults to 5000.

    Returns:
        pd.DataFrame: Shuffled DataFrame containing the prepared dataset with Ticket_Id.
    """
    df = pd.read_csv(file_path)
    df['Ticket_Id'] = range(1, len(df) + 1)
    df = df.sample(frac=1, random_state=42).reset_index(drop=True)  # Shuffle the dataset
    df = df.head(num_tickets)  # Limit to the specified number of tickets
    print(f"Dataset loaded, shuffled, and limited to {num_tickets} tickets. Shape: {df.shape}")
    print(f"Columns: {df.columns.tolist()}")
    return df

def process_dataset_in_chunks(df: pd.DataFrame, chunk_size: int = 10) -> pd.DataFrame:
    """
    Process the dataset in chunks, predicting intents for each chunk.

    Args:
        df (pd.DataFrame): Input DataFrame containing the dataset.
        chunk_size (int): Number of tickets to process in each batch.

    Returns:
        pd.DataFrame: DataFrame with predicted intents added.
    """
    predictor = IntentPredictor()
    
    def create_tickets(dataframe: pd.DataFrame) -> Iterator[Ticket]:
        """Create Ticket objects from DataFrame rows."""
        return (Ticket(ticket_id=row.Ticket_Id, content=row.instruction)
                for row in dataframe.itertuples())

    def predict_chunk(tickets: List[Ticket]) -> List[PredictedTicket]:
        """Predict intents for a chunk of tickets."""
        return predictor.predict_intents(tickets).predictions

    def chunk_iterator(iterable: Iterable, size: int) -> Iterator[List]:
        """Yield chunks of the given size from the iterable."""
        iterator = iter(iterable)
        return iter(lambda: list(itertools.islice(iterator, size)), [])

    def process_chunks(tickets: Iterator[Ticket]) -> Iterator[PredictedTicket]:
        """Process tickets in chunks and yield predictions."""
        total_chunks = (len(df) + chunk_size - 1) // chunk_size
        for chunk in tqdm(chunk_iterator(tickets, chunk_size), total=total_chunks, desc="Processing chunks"):
            yield from predict_chunk(chunk)

    tickets = create_tickets(df)
    predictions = process_chunks(tickets)
    
    # Create a dictionary of predictions
    prediction_dict = {pred.ticket_id: pred.predicted_intent for pred in predictions}
    
    # Add predictions to the DataFrame
    return df.assign(predicted_intent=df['Ticket_Id'].map(prediction_dict))

if __name__ == "__main__":
    file_path = "updated_customer_support_dataset.csv"
    prepared_dataset = read_prepared_dataset(file_path, num_tickets=5000)
    
    processed_dataset = process_dataset_in_chunks(prepared_dataset, chunk_size=200)
    print(processed_dataset.head())
    
    processed_dataset.to_csv("dataset_with_predictions_5k.csv", index=False)
    print("Dataset with predictions saved to 'dataset_with_predictions_5k.csv'")
